#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£ç¾é£Ÿ CNN åˆ†é¡ - æ‰‹å‹•ç¡¬é«”é¸æ“‡è¨“ç·´å·¥å…·
Taiwan Food CNN Classification - Manual Hardware Selection Training Tool

æ”¯æ´æ‰‹å‹•é¸æ“‡è¨“ç·´ç¡¬é«”ï¼ŒåŒ…æ‹¬ GPUã€CPU
"""

import torch
import torch.nn as nn
import torch.optim as optim
from pytorch_model import TaiwanFoodResNet50
from pytorch_data_loader import get_dataloaders
from tqdm import tqdm
import os

def detect_training_devices():
    """æª¢æ¸¬å¯ç”¨çš„è¨“ç·´è£ç½®"""
    print("ğŸ” æª¢æ¸¬å¯ç”¨çš„è¨“ç·´è£ç½®")
    print("=" * 50)
    
    devices = []
    device_info = []
    
    # æª¢æ¸¬ GPU
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        for i in range(gpu_count):
            device_name = torch.cuda.get_device_name(i)
            memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            devices.append(f'cuda:{i}')
            device_info.append(f"âœ… GPU {i}: {device_name} ({memory:.1f} GB)")
    else:
        device_info.append("âŒ æœªæª¢æ¸¬åˆ° CUDA GPU")
    
    # æª¢æ¸¬ MPS (Apple Silicon)
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        devices.append('mps')
        device_info.append("ğŸ MPS (Apple Silicon) å¯ç”¨")
    
    # CPU å§‹çµ‚å¯ç”¨
    devices.append('cpu')
    device_info.append("ğŸ’» CPU å¯ç”¨")
    
    # é¡¯ç¤ºæª¢æ¸¬çµæœ
    for info in device_info:
        print(info)
    
    print("=" * 50)
    return devices

def choose_training_device(available_devices, manual_mode=False):
    """é¸æ“‡è¨“ç·´è£ç½®"""
    print("\nğŸ¯ é¸æ“‡è¨“ç·´è£ç½®")
    print("-" * 40)
    
    # æº–å‚™é¸é …
    options = []
    for device in available_devices:
        if device.startswith('cuda:'):
            gpu_idx = device.split(':')[1]
            gpu_name = torch.cuda.get_device_name(int(gpu_idx))
            memory = torch.cuda.get_device_properties(int(gpu_idx)).total_memory / 1024**3
            options.append((device, f"ğŸš€ {gpu_name} ({memory:.1f} GB)"))
        elif device == 'mps':
            options.append((device, "ğŸ Apple Silicon MPS"))
        elif device == 'cpu':
            options.append((device, "ğŸ’» CPU (è¼ƒæ…¢ä½†ç©©å®š)"))
    
    print("å¯ç”¨çš„è¨“ç·´è£ç½®:")
    for i, (device, desc) in enumerate(options):
        print(f"  {i}. {desc}")
    
    if manual_mode:
        # æ‰‹å‹•é¸æ“‡æ¨¡å¼
        print(f"\nè«‹é¸æ“‡è¦ä½¿ç”¨çš„è£ç½® (0-{len(options)-1}):")
        print("æˆ–ç›´æ¥æŒ‰ Enter ä½¿ç”¨è‡ªå‹•é¸æ“‡")
        
        while True:
            try:
                user_input = input("ğŸ‘‰ è«‹è¼¸å…¥é¸é …ç·¨è™Ÿ: ").strip()
                
                if user_input == "":
                    # ä½¿ç”¨è€…é¸æ“‡è‡ªå‹•æ¨¡å¼
                    print("ğŸ¤– ä½¿ç”¨è‡ªå‹•é¸æ“‡æ¨¡å¼")
                    break
                
                choice_idx = int(user_input)
                if 0 <= choice_idx < len(options):
                    chosen_device = options[choice_idx][0]
                    print(f"\nâœ… æ‰‹å‹•é¸æ“‡: {options[choice_idx][1]}")
                    return chosen_device
                else:
                    print(f"âš ï¸  è«‹è¼¸å…¥ 0-{len(options)-1} ä¹‹é–“çš„æ•¸å­—")
                    
            except ValueError:
                print("âš ï¸  è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
            except KeyboardInterrupt:
                print("\n\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                return None
    
    # è‡ªå‹•é¸æ“‡æœ€ä½³è£ç½®
    for device, desc in options:
        if device.startswith('cuda:'):
            print(f"\nğŸ¤– è‡ªå‹•é¸æ“‡: {desc}")
            return device
    
    if 'mps' in available_devices:
        print(f"\nğŸ¤– è‡ªå‹•é¸æ“‡: Apple Silicon MPS")
        return 'mps'
    
    print(f"\nğŸ¤– è‡ªå‹•é¸æ“‡: CPU")
    return 'cpu'

def choose_model_to_continue():
    """é¸æ“‡è¦ç¹¼çºŒè¨“ç·´çš„æ¨¡å‹"""
    print("\nğŸ¯ é¸æ“‡è¨“ç·´æ¨¡å¼")
    print("-" * 40)
    
    if not os.path.exists('models'):
        os.makedirs('models')
        print("ğŸ“ å·²å»ºç«‹ models è³‡æ–™å¤¾")
        return None, None
    
    model_files = [f for f in os.listdir('models') if f.endswith('.pth')]
    
    if not model_files:
        print("ğŸ“ æ²’æœ‰æ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œå°‡é–‹å§‹æ–°çš„è¨“ç·´")
        return None, None
    
    print("å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ:")
    print("  0. ğŸ†• é–‹å§‹æ–°çš„è¨“ç·´")
    for i, model_file in enumerate(model_files, 1):
        print(f"  {i}. ğŸ“ {model_file}")
    
    while True:
        try:
            choice = input(f"\nğŸ‘‰ è«‹é¸æ“‡ (0-{len(model_files)}): ").strip()
            choice_idx = int(choice)
            
            if choice_idx == 0:
                return None, None
            elif 1 <= choice_idx <= len(model_files):
                selected_model = model_files[choice_idx - 1]
                model_path = os.path.join('models', selected_model)
                
                # å˜—è©¦å¾æª”åè§£æ epoch
                try:
                    if 'epoch' in selected_model.lower():
                        epoch_str = selected_model.lower().split('epoch')[1].split('_')[0].split('.')[0]
                        start_epoch = int(epoch_str) + 1
                    else:
                        start_epoch = 1
                except:
                    start_epoch = 1
                
                print(f"âœ… å°‡å¾ {selected_model} ç¹¼çºŒè¨“ç·´ (å¾ç¬¬ {start_epoch} epoch é–‹å§‹)")
                return model_path, start_epoch
            else:
                print(f"âš ï¸  è«‹è¼¸å…¥ 0-{len(model_files)} ä¹‹é–“çš„æ•¸å­—")
                
        except ValueError:
            print("âš ï¸  è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
        except KeyboardInterrupt:
            print("\n\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
            return None, None

def train_model_with_device(device, model_path=None, start_epoch=1, num_epochs=50, batch_size=32):
    """ä½¿ç”¨æŒ‡å®šè£ç½®è¨“ç·´æ¨¡å‹"""
    
    print(f"\nğŸš€ é–‹å§‹è¨“ç·´è¨­å®š")
    print(f"   è¨“ç·´è£ç½®: {device}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   ç¸½ Epochs: {num_epochs}")
    print(f"   èµ·å§‹ Epoch: {start_epoch}")
    
    # å¦‚æœæ˜¯ CPUï¼Œèª¿æ•´æ‰¹æ¬¡å¤§å°
    if device == 'cpu':
        batch_size = min(batch_size, 16)
        print(f"   CPU æœ€ä½³åŒ–: èª¿æ•´æ‰¹æ¬¡å¤§å°ç‚º {batch_size}")
    
    # è¨­å®šè£ç½®
    device_obj = torch.device(device)
    
    # å»ºç«‹è³‡æ–™è¼‰å…¥å™¨
    print("\nğŸ“‚ è¼‰å…¥è³‡æ–™é›†...")
    train_loader, val_loader, num_classes = get_dataloaders(
        train_csv='archive/tw_food_101/tw_food_101_train.csv',
        train_img_dir='archive/tw_food_101/train',
        batch_size=batch_size,
        val_split=0.2
    )
    
    print(f"âœ… è¨“ç·´é›†: {len(train_loader.dataset)} å¼µåœ–ç‰‡")
    print(f"âœ… é©—è­‰é›†: {len(val_loader.dataset)} å¼µåœ–ç‰‡")
    print(f"âœ… é¡åˆ¥æ•¸: {num_classes}")
    
    # å»ºç«‹æ¨¡å‹
    model = TaiwanFoodResNet50(num_classes=num_classes)
    
    # è¼‰å…¥é è¨“ç·´æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
    if model_path and os.path.exists(model_path):
        try:
            state_dict = torch.load(model_path, map_location='cpu')
            model.load_state_dict(state_dict)
            print(f"âœ… æˆåŠŸè¼‰å…¥é è¨“ç·´æ¨¡å‹: {model_path}")
        except Exception as e:
            print(f"âš ï¸  è¼‰å…¥é è¨“ç·´æ¨¡å‹å¤±æ•—: {e}")
            print("ğŸ”„ å°‡é–‹å§‹æ–°çš„è¨“ç·´")
            start_epoch = 1
    
    model = model.to(device_obj)
    
    # è¨­å®šæå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)
    
    # è¨“ç·´è¿´åœˆ
    best_val_acc = 0.0
    
    print(f"\nğŸ¯ é–‹å§‹è¨“ç·´ (è£ç½®: {device})")
    print("=" * 60)
    
    for epoch in range(start_epoch, num_epochs + 1):
        # è¨“ç·´éšæ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{num_epochs} - è¨“ç·´", ncols=100)
        
        for images, labels in train_pbar:
            images, labels = images.to(device_obj), labels.to(device_obj)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_correct += predicted.eq(labels).sum().item()
            
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100. * train_correct / ((train_pbar.n + 1) * batch_size):.2f}%'
            })
        
        # é©—è­‰éšæ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch}/{num_epochs} - é©—è­‰", ncols=100)
            
            for images, labels in val_pbar:
                images, labels = images.to(device_obj), labels.to(device_obj)
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_correct += predicted.eq(labels).sum().item()
                
                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{100. * val_correct / ((val_pbar.n + 1) * batch_size):.2f}%'
                })
        
        # è¨ˆç®—å¹³å‡æŒ‡æ¨™
        train_acc = 100. * train_correct / len(train_loader.dataset)
        val_acc = 100. * val_correct / len(val_loader.dataset)
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        print(f"\nEpoch {epoch:3d} | è¨“ç·´ Loss: {avg_train_loss:.4f} | è¨“ç·´ Acc: {train_acc:.2f}% | é©—è­‰ Loss: {avg_val_loss:.4f} | é©—è­‰ Acc: {val_acc:.2f}%")
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_path = f'models/best_model_epoch{epoch}_acc{val_acc:.2f}.pth'
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹ï¼é©—è­‰æº–ç¢ºç‡: {val_acc:.2f}%")
        
        # æ¯10å€‹epochå„²å­˜ä¸€æ¬¡
        if epoch % 10 == 0:
            checkpoint_path = f'models/checkpoint_epoch{epoch}.pth'
            torch.save(model.state_dict(), checkpoint_path)
            print(f"ğŸ’¾ æª¢æŸ¥é»å·²å„²å­˜: {checkpoint_path}")
        
        scheduler.step()
        print("-" * 60)
    
    print(f"\nğŸ‰ è¨“ç·´å®Œæˆï¼æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.2f}%")

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸœ å°ç£ç¾é£Ÿ CNN åˆ†é¡ - æ‰‹å‹•ç¡¬é«”é¸æ“‡è¨“ç·´å·¥å…·")
    print("Taiwan Food CNN Classification - Manual Hardware Selection Training")
    print("=" * 80)
    
    # æª¢æ¸¬å¯ç”¨è£ç½®
    available_devices = detect_training_devices()
    
    # é¸æ“‡æ¨¡å¼
    print("\nğŸ® è«‹é¸æ“‡è¨“ç·´ç¡¬é«”é¸æ“‡æ¨¡å¼:")
    print("  1. ğŸ¤– è‡ªå‹•æ¨¡å¼ (ç³»çµ±è‡ªå‹•é¸æ“‡æœ€ä½³ç¡¬é«”)")
    print("  2. ğŸ® æ‰‹å‹•æ¨¡å¼ (æ‰‹å‹•é¸æ“‡è¨“ç·´ç¡¬é«”)")
    print("  3. âŒ é€€å‡ºç¨‹å¼")
    
    while True:
        try:
            mode_choice = input("\nğŸ‘‰ è«‹é¸æ“‡æ¨¡å¼ (1-3): ").strip()
            
            if mode_choice == "1":
                print("\nğŸ¤– ä½¿ç”¨è‡ªå‹•æ¨¡å¼")
                manual_mode = False
                break
            elif mode_choice == "2":
                print("\nğŸ® ä½¿ç”¨æ‰‹å‹•æ¨¡å¼")
                manual_mode = True
                break
            elif mode_choice == "3":
                print("\nğŸ‘‹ ç¨‹å¼çµæŸ")
                return
            else:
                print("âš ï¸  è«‹è¼¸å…¥ 1ã€2 æˆ– 3")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼çµæŸ")
            return
    
    # é¸æ“‡è¨“ç·´è£ç½®
    device = choose_training_device(available_devices, manual_mode)
    if device is None:
        print("âŒ æœªé¸æ“‡è£ç½®ï¼Œç¨‹å¼çµæŸ")
        return
    
    # é¸æ“‡æ¨¡å‹
    model_path, start_epoch = choose_model_to_continue()
    
    # è¨­å®šè¨“ç·´åƒæ•¸
    print(f"\nâš™ï¸  è¨“ç·´åƒæ•¸è¨­å®š:")
    
    try:
        epochs = input("ğŸ“… è¨“ç·´ Epochs (é è¨­ 50): ").strip()
        num_epochs = int(epochs) if epochs else 50
        
        batch = input("ğŸ“¦ æ‰¹æ¬¡å¤§å° (é è¨­ 32): ").strip()
        batch_size = int(batch) if batch else 32
        
    except ValueError:
        print("âš ï¸  ä½¿ç”¨é è¨­åƒæ•¸")
        num_epochs = 50
        batch_size = 32
    
    print(f"\nğŸ“‹ æœ€çµ‚è¨­å®š:")
    print(f"   è¨“ç·´è£ç½®: {device}")
    print(f"   è¨“ç·´ Epochs: {num_epochs}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    if model_path:
        print(f"   ç¹¼çºŒè¨“ç·´: {model_path}")
    else:
        print(f"   è¨“ç·´æ¨¡å¼: å…¨æ–°è¨“ç·´")
    
    # ç¢ºèªé–‹å§‹è¨“ç·´
    confirm = input("\nğŸš€ æ˜¯å¦é–‹å§‹è¨“ç·´ï¼Ÿ (Y/n): ").strip().lower()
    if confirm in ['n', 'no']:
        print("âŒ ä½¿ç”¨è€…å–æ¶ˆè¨“ç·´")
        return
    
    # é–‹å§‹è¨“ç·´
    try:
        train_model_with_device(device, model_path, start_epoch, num_epochs, batch_size)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  è¨“ç·´è¢«ä½¿ç”¨è€…ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == '__main__':
    main()