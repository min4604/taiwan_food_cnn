import torch
import numpy as np
from torchvision import transforms
from PIL import Image
import os

class AMDNPUInference:
    """
    AMD Ryzen AI 9HX NPU æ¨ç†é¡
    ä½¿ç”¨ ONNX Runtime DirectML é€²è¡Œ NPU æ¨ç†
    """
    
    def __init__(self, model_path, img_size=224):
        self.img_size = img_size
        self.onnx_model_path = None
        self.ort_session = None
        self.pytorch_model = None
        
        # è¨­å®šè½‰æ›
        self.transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._setup_model(model_path)
    
    def _setup_model(self, pytorch_model_path):
        """è¨­å®š AMD NPU æ¨ç†æ¨¡å‹"""
        try:
            # æª¢æŸ¥æ˜¯å¦æ”¯æ´ ONNX Runtime DirectML
            import onnxruntime as ort
            providers = ort.get_available_providers()
            
            if 'DmlExecutionProvider' not in providers:
                raise RuntimeError("DirectML ä¸å¯ç”¨ï¼Œç„¡æ³•ä½¿ç”¨ AMD NPU")
            
            print("âœ… æª¢æ¸¬åˆ° DirectML æ”¯æ´")
            print("ğŸš€ ç‚º AMD Ryzen AI 9 HX 370 NPU æœ€ä½³åŒ–...")
            
            # è½‰æ› PyTorch æ¨¡å‹ç‚º ONNX (å¦‚æœéœ€è¦)
            onnx_path = self._convert_to_onnx(pytorch_model_path)
            
            # å»ºç«‹ ONNX Runtime æœƒè©±ï¼Œå°ˆç‚º AMD NPU æœ€ä½³åŒ–
            providers = [
                ('DmlExecutionProvider', {
                    'device_id': 0,
                    'enable_dynamic_shapes': True
                }),
                'CPUExecutionProvider'   # CPU ä½œç‚ºå‚™æ´
            ]
            
            # å»ºç«‹æœƒè©±é¸é …ä»¥æœ€ä½³åŒ–æ•ˆèƒ½
            session_options = ort.SessionOptions()
            session_options.enable_mem_pattern = True
            session_options.enable_cpu_mem_arena = True
            session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            
            self.ort_session = ort.InferenceSession(
                onnx_path, 
                providers=providers,
                sess_options=session_options
            )
            print(f"ğŸš€ AMD NPU æ¨ç†æœƒè©±å·²å»ºç«‹")
            print(f"ğŸ“Š ä½¿ç”¨æä¾›è€…: {self.ort_session.get_providers()}")
            
        except ImportError:
            print("âŒ ONNX Runtime æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ install_amd_npu.bat")
            self._setup_cpu_fallback(pytorch_model_path)
        except Exception as e:
            print(f"âŒ AMD NPU è¨­å®šå¤±æ•—: {e}")
            print("ğŸ’¡ å°‡å›é€€åˆ° CPU æ¨ç†")
            self._setup_cpu_fallback(pytorch_model_path)
    
    def _convert_to_onnx(self, pytorch_model_path):
        """å°‡ PyTorch æ¨¡å‹è½‰æ›ç‚º ONNX æ ¼å¼"""
        onnx_path = pytorch_model_path.replace('.pth', '_amd_npu.onnx')
        
        if os.path.exists(onnx_path):
            print(f"ğŸ“ ä½¿ç”¨ç¾æœ‰çš„ ONNX æ¨¡å‹: {onnx_path}")
            return onnx_path
        
        print("ğŸ”„ è½‰æ› PyTorch æ¨¡å‹ç‚º ONNX...")
        
        try:
            from pytorch_model import TaiwanFoodResNet50
            
            # è¼‰å…¥ PyTorch æ¨¡å‹
            model = TaiwanFoodResNet50(num_classes=101)
            model.load_state_dict(torch.load(pytorch_model_path, map_location='cpu'))
            model.eval()
            
            # å»ºç«‹ç¯„ä¾‹è¼¸å…¥
            dummy_input = torch.randn(1, 3, self.img_size, self.img_size)
            
            # åŒ¯å‡ºç‚º ONNX
            torch.onnx.export(
                model,
                dummy_input,
                onnx_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes={
                    'input': {0: 'batch_size'},
                    'output': {0: 'batch_size'}
                }
            )
            
            print(f"âœ… ONNX æ¨¡å‹å·²å„²å­˜: {onnx_path}")
            return onnx_path
            
        except Exception as e:
            print(f"âŒ ONNX è½‰æ›å¤±æ•—: {e}")
            raise
    
    def _setup_cpu_fallback(self, pytorch_model_path):
        """è¨­å®š CPU å‚™æ´æ¨ç†"""
        try:
            from pytorch_model import TaiwanFoodResNet50
            
            self.pytorch_model = TaiwanFoodResNet50(num_classes=101)
            self.pytorch_model.load_state_dict(torch.load(pytorch_model_path, map_location='cpu'))
            self.pytorch_model.eval()
            print("ğŸ”„ å·²è¨­å®š CPU å‚™æ´æ¨ç†")
        except Exception as e:
            print(f"âŒ CPU å‚™æ´è¨­å®šå¤±æ•—: {e}")
    
    def predict_image(self, image_path):
        """ä½¿ç”¨ AMD NPU é€²è¡Œåœ–ç‰‡æ¨ç†"""
        try:
            # è¼‰å…¥å’Œé è™•ç†åœ–ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0)
            input_array = input_tensor.numpy()
            
            if self.ort_session:
                # ä½¿ç”¨ ONNX Runtime (AMD NPU)
                input_name = self.ort_session.get_inputs()[0].name
                result = self.ort_session.run(None, {input_name: input_array})
                output = result[0]
                predicted_class = np.argmax(output, axis=1)[0]
            else:
                # ä½¿ç”¨ PyTorch CPU å‚™æ´
                with torch.no_grad():
                    output = self.pytorch_model(input_tensor)
                    predicted_class = torch.argmax(output, dim=1).item()
            
            return predicted_class
            
        except Exception as e:
            print(f"âŒ æ¨ç†å¤±æ•—: {e}")
            return -1

def test_amd_npu():
    """æ¸¬è©¦ AMD NPU åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦ AMD Ryzen AI 9HX NPU åŠŸèƒ½")
    print("=" * 50)
    
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        print(f"ğŸ“‹ å¯ç”¨æä¾›è€…: {providers}")
        
        if 'DmlExecutionProvider' in providers:
            print("âœ… DirectML å¯ç”¨ - AMD NPU æ”¯æ´æ­£å¸¸")
        else:
            print("âŒ DirectML ä¸å¯ç”¨")
            print("ğŸ’¡ è«‹åŸ·è¡Œ install_amd_npu.bat å®‰è£æ”¯æ´å¥—ä»¶")
            
    except ImportError:
        print("âŒ ONNX Runtime æœªå®‰è£")
        print("ğŸ’¡ è«‹åŸ·è¡Œ install_amd_npu.bat å®‰è£")
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")

if __name__ == '__main__':
    test_amd_npu()