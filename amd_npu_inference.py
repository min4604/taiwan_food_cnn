import torch
import numpy as np
from torchvision import transforms
from PIL import Image
import os

class AMDNPUInference:
    """
    AMD Ryzen AI 9HX NPU æ¨ç†é¡
    ä½¿ç”¨ ONNX Runtime DirectML é€²è¡Œ NPU æ¨ç†
    """
    
    def __init__(self, model_path, img_size=224):
        self.img_size = img_size
        self.onnx_model_path = None
        self.ort_session = None
        self.pytorch_model = None
        
        # è¨­å®šè½‰æ›
        self.transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._setup_model(model_path)
    
    def _setup_model(self, pytorch_model_path):
        """è¨­å®š AMD NPU æ¨ç†æ¨¡å‹"""
        try:
            # æª¢æŸ¥æ˜¯å¦æ”¯æ´ ONNX Runtime DirectML
            import onnxruntime as ort
            providers = ort.get_available_providers()
            
            if 'DmlExecutionProvider' not in providers:
                raise RuntimeError("DirectML ä¸å¯ç”¨ï¼Œç„¡æ³•ä½¿ç”¨ AMD NPU")
            
            print("âœ… æª¢æ¸¬åˆ° DirectML æ”¯æ´")
            
            # è½‰æ› PyTorch æ¨¡å‹ç‚º ONNX (å¦‚æœéœ€è¦)
            onnx_path = self._convert_to_onnx(pytorch_model_path)
            
            # å»ºç«‹ ONNX Runtime æœƒè©±
            providers = [
                'DmlExecutionProvider',  # DirectML (AMD NPU)
                'CPUExecutionProvider'   # CPU ä½œç‚ºå‚™æ´
            ]
            
            self.ort_session = ort.InferenceSession(onnx_path, providers=providers)
            print(f"ğŸš€ AMD NPU æ¨ç†æœƒè©±å·²å»ºç«‹")
            print(f"ğŸ“Š ä½¿ç”¨æä¾›è€…: {self.ort_session.get_providers()}")
            
        except ImportError:
            print("âŒ ONNX Runtime æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ install_amd_npu.bat")
            raise
        except Exception as e:
            print(f"âŒ AMD NPU è¨­å®šå¤±æ•—: {e}")
            print("ğŸ’¡ å°‡å›é€€åˆ° CPU æ¨ç†")
            self._setup_cpu_fallback(pytorch_model_path)
    
    def _convert_to_onnx(self, pytorch_model_path):
        """å°‡ PyTorch æ¨¡å‹è½‰æ›ç‚º ONNX æ ¼å¼"""
        onnx_path = pytorch_model_path.replace('.pth', '_amd_npu.onnx')
        
        if os.path.exists(onnx_path):
            print(f"ğŸ“ ä½¿ç”¨ç¾æœ‰çš„ ONNX æ¨¡å‹: {onnx_path}")
            return onnx_path
        
        print("ğŸ”„ è½‰æ› PyTorch æ¨¡å‹ç‚º ONNX...")
        
        try:
            from pytorch_model import TaiwanFoodResNet50
            
            # è¼‰å…¥ PyTorch æ¨¡å‹
            model = TaiwanFoodResNet50(num_classes=101)
            model.load_state_dict(torch.load(pytorch_model_path, map_location='cpu'))
            model.eval()
            
            # å»ºç«‹ç¯„ä¾‹è¼¸å…¥
            dummy_input = torch.randn(1, 3, self.img_size, self.img_size)\n            \n            # åŒ¯å‡ºç‚º ONNX\n            torch.onnx.export(\n                model,\n                dummy_input,\n                onnx_path,\n                export_params=True,\n                opset_version=11,\n                do_constant_folding=True,\n                input_names=['input'],\n                output_names=['output'],\n                dynamic_axes={\n                    'input': {0: 'batch_size'},\n                    'output': {0: 'batch_size'}\n                }\n            )\n            \n            print(f\"âœ… ONNX æ¨¡å‹å·²å„²å­˜: {onnx_path}\")\n            return onnx_path\n            \n        except Exception as e:\n            print(f\"âŒ ONNX è½‰æ›å¤±æ•—: {e}\")\n            raise\n    \n    def _setup_cpu_fallback(self, pytorch_model_path):\n        \"\"\"è¨­å®š CPU å‚™æ´æ¨ç†\"\"\"\n        from pytorch_model import TaiwanFoodResNet50\n        \n        self.pytorch_model = TaiwanFoodResNet50(num_classes=101)\n        self.pytorch_model.load_state_dict(torch.load(pytorch_model_path, map_location='cpu'))\n        self.pytorch_model.eval()\n        print(\"ğŸ”„ å·²è¨­å®š CPU å‚™æ´æ¨ç†\")\n    \n    def predict_image(self, image_path):\n        \"\"\"ä½¿ç”¨ AMD NPU é€²è¡Œåœ–ç‰‡æ¨ç†\"\"\"\n        try:\n            # è¼‰å…¥å’Œé è™•ç†åœ–ç‰‡\n            image = Image.open(image_path).convert('RGB')\n            input_tensor = self.transform(image).unsqueeze(0)\n            input_array = input_tensor.numpy()\n            \n            if self.ort_session:\n                # ä½¿ç”¨ ONNX Runtime (AMD NPU)\n                input_name = self.ort_session.get_inputs()[0].name\n                result = self.ort_session.run(None, {input_name: input_array})\n                output = result[0]\n                predicted_class = np.argmax(output, axis=1)[0]\n            else:\n                # ä½¿ç”¨ PyTorch CPU å‚™æ´\n                with torch.no_grad():\n                    output = self.pytorch_model(input_tensor)\n                    predicted_class = torch.argmax(output, dim=1).item()\n            \n            return predicted_class\n            \n        except Exception as e:\n            print(f\"âŒ æ¨ç†å¤±æ•—: {e}\")\n            return -1\n    \n    def predict_batch(self, image_paths):\n        \"\"\"æ‰¹æ¬¡æ¨ç†\"\"\"\n        predictions = []\n        \n        for img_path in image_paths:\n            pred = self.predict_image(img_path)\n            predictions.append(pred)\n        \n        return predictions\n\ndef test_amd_npu():\n    \"\"\"æ¸¬è©¦ AMD NPU åŠŸèƒ½\"\"\"\n    print(\"ğŸ§ª æ¸¬è©¦ AMD Ryzen AI 9HX NPU åŠŸèƒ½\")\n    print(\"=\" * 50)\n    \n    try:\n        import onnxruntime as ort\n        providers = ort.get_available_providers()\n        print(f\"ğŸ“‹ å¯ç”¨æä¾›è€…: {providers}\")\n        \n        if 'DmlExecutionProvider' in providers:\n            print(\"âœ… DirectML å¯ç”¨ - AMD NPU æ”¯æ´æ­£å¸¸\")\n            \n            # æ¸¬è©¦å»ºç«‹æœƒè©±\n            dummy_model = \"test_model.onnx\"\n            # é€™è£¡å¯ä»¥æ·»åŠ å¯¦éš›çš„æ¨¡å‹æ¸¬è©¦\n            \n        else:\n            print(\"âŒ DirectML ä¸å¯ç”¨\")\n            print(\"ğŸ’¡ è«‹åŸ·è¡Œ install_amd_npu.bat å®‰è£æ”¯æ´å¥—ä»¶\")\n            \n    except ImportError:\n        print(\"âŒ ONNX Runtime æœªå®‰è£\")\n        print(\"ğŸ’¡ è«‹åŸ·è¡Œ install_amd_npu.bat å®‰è£\")\n    except Exception as e:\n        print(f\"âŒ æ¸¬è©¦å¤±æ•—: {e}\")\n\nif __name__ == '__main__':\n    test_amd_npu()