#!/usr/bin/env python3
"""
AMD NPU å¿«é€Ÿé©—è­‰è…³æœ¬
"""

import torch
import numpy as np
from torchvision import transforms
from PIL import Image
import os

def quick_amd_npu_test():
    """å¿«é€Ÿæ¸¬è©¦ AMD NPU åŠŸèƒ½"""
    print("ğŸš€ AMD NPU å¿«é€ŸåŠŸèƒ½é©—è­‰")
    print("=" * 40)
    
    try:
        # æª¢æŸ¥ ONNX Runtime DirectML
        import onnxruntime as ort
        providers = ort.get_available_providers()
        
        print(f"å¯ç”¨æä¾›è€…: {providers}")
        
        if 'DmlExecutionProvider' not in providers:
            print("âŒ DirectML ä¸å¯ç”¨")
            return False
        
        print("âœ… DirectML å¯ç”¨")
        
        # å˜—è©¦å»ºç«‹ç°¡å–®çš„æ¨ç†æœƒè©±
        try:
            # å»ºç«‹ä¸€å€‹æœ€ç°¡å–®çš„ ONNX æ¨¡å‹ä¾†æ¸¬è©¦
            import onnx
            from onnx import helper, TensorProto
            
            # å»ºç«‹ç°¡å–®çš„æ†ç­‰é‹ç®—æ¨¡å‹
            X = helper.make_tensor_value_info('X', TensorProto.FLOAT, [1, 3, 224, 224])
            Y = helper.make_tensor_value_info('Y', TensorProto.FLOAT, [1, 3, 224, 224])
            
            identity_node = helper.make_node(
                'Identity',
                inputs=['X'],
                outputs=['Y'],
            )
            
            graph = helper.make_graph(
                [identity_node],
                'test_graph',
                [X],
                [Y]
            )
            
            model = helper.make_model(graph)
            
            # å„²å­˜æ¸¬è©¦æ¨¡å‹
            test_model_path = 'test_amd_npu_model.onnx'
            onnx.save(model, test_model_path)
            
            # å»ºç«‹ DirectML æœƒè©±
            session = ort.InferenceSession(
                test_model_path, 
                providers=['DmlExecutionProvider', 'CPUExecutionProvider']
            )
            
            print(f"âœ… ONNX æœƒè©±å»ºç«‹æˆåŠŸ")
            print(f"ğŸ¯ ä½¿ç”¨æä¾›è€…: {session.get_providers()}")
            
            # æ¸¬è©¦æ¨ç†
            dummy_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
            result = session.run(None, {'X': dummy_input})
            
            print("âœ… AMD NPU æ¨ç†æ¸¬è©¦æˆåŠŸ")
            print(f"ğŸ“Š è¼¸å…¥å½¢ç‹€: {dummy_input.shape}")
            print(f"ğŸ“Š è¼¸å‡ºå½¢ç‹€: {result[0].shape}")
            
            # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
            if os.path.exists(test_model_path):
                os.remove(test_model_path)
            
            return True
            
        except Exception as e:
            print(f"âŒ ONNX æ¨ç†æ¸¬è©¦å¤±æ•—: {e}")
            return False
            
    except ImportError as e:
        print(f"âŒ å¥—ä»¶å°å…¥å¤±æ•—: {e}")
        return False
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_pytorch_model_conversion():
    """æ¸¬è©¦ PyTorch æ¨¡å‹è½‰æ›"""
    print("\nğŸ”„ PyTorch æ¨¡å‹è½‰æ›æ¸¬è©¦")
    print("-" * 30)
    
    try:
        from pytorch_model import TaiwanFoodResNet50
        
        # å»ºç«‹æ¸¬è©¦æ¨¡å‹
        model = TaiwanFoodResNet50(num_classes=101)
        model.eval()
        
        # å»ºç«‹ç¯„ä¾‹è¼¸å…¥
        dummy_input = torch.randn(1, 3, 224, 224)
        
        # æ¸¬è©¦æ¨¡å‹å‰å‘å‚³æ’­
        with torch.no_grad():
            output = model(dummy_input)
        
        print(f"âœ… PyTorch æ¨¡å‹æ¸¬è©¦æˆåŠŸ")
        print(f"ğŸ“Š è¼¸å…¥å½¢ç‹€: {dummy_input.shape}")
        print(f"ğŸ“Š è¼¸å‡ºå½¢ç‹€: {output.shape}")
        
        # æ¸¬è©¦ ONNX å°å‡º
        test_onnx_path = 'test_conversion.onnx'
        
        torch.onnx.export(
            model,
            dummy_input,
            test_onnx_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output']
        )
        
        print(f"âœ… ONNX å°å‡ºæˆåŠŸ: {test_onnx_path}")
        
        # é©—è­‰å°å‡ºçš„ ONNX æ¨¡å‹
        import onnx
        onnx_model = onnx.load(test_onnx_path)
        onnx.checker.check_model(onnx_model)
        
        print("âœ… ONNX æ¨¡å‹é©—è­‰é€šé")
        
        # æ¸…ç†
        if os.path.exists(test_onnx_path):
            os.remove(test_onnx_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ PyTorch æ¨¡å‹è½‰æ›æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª AMD Ryzen AI NPU å®Œæ•´åŠŸèƒ½æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦ 1: AMD NPU åŸºæœ¬åŠŸèƒ½
    npu_ok = quick_amd_npu_test()
    
    # æ¸¬è©¦ 2: PyTorch æ¨¡å‹è½‰æ›
    conversion_ok = test_pytorch_model_conversion()
    
    # ç¸½çµ
    print("\nğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 30)
    print(f"AMD NPU åŸºæœ¬åŠŸèƒ½: {'âœ… é€šé' if npu_ok else 'âŒ å¤±æ•—'}")
    print(f"PyTorch æ¨¡å‹è½‰æ›: {'âœ… é€šé' if conversion_ok else 'âŒ å¤±æ•—'}")
    
    if npu_ok and conversion_ok:
        print("\nğŸ‰ æ­å–œï¼AMD NPU å®Œå…¨å°±ç·’ï¼")
        print("æ‚¨å¯ä»¥é–‹å§‹ä½¿ç”¨ AMD NPU é€²è¡Œæ·±åº¦å­¸ç¿’æ¨ç†äº†ï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("python evaluate_test_set.py  # ä½¿ç”¨ AMD NPU è©•ä¼°æ¨¡å‹")
    else:
        print("\nâš ï¸  éƒ¨åˆ†åŠŸèƒ½æ¸¬è©¦å¤±æ•—")
        print("è«‹æª¢æŸ¥ç›¸é—œå¥—ä»¶å®‰è£æˆ–è¯ç¹«æ”¯æ´")

if __name__ == '__main__':
    main()