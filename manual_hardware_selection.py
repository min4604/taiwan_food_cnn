#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£ç¾é£Ÿ CNN åˆ†é¡ - æ‰‹å‹•ç¡¬é«”é¸æ“‡æ¨ç†å·¥å…·
Taiwan Food CNN Classification - Manual Hardware Selection Inference Tool

æ”¯æ´æ‰‹å‹•é¸æ“‡æ¨ç†ç¡¬é«”ï¼ŒåŒ…æ‹¬ AMD Ryzen AI NPUã€GPUã€CPU
"""

import os
import sys
import glob
from evaluate_test_set import detect_available_devices, choose_device, evaluate_with_amd_npu, evaluate_standard_mode

def manual_device_inference():
    """
    æ‰‹å‹•é¸æ“‡ç¡¬é«”é€²è¡Œæ¨ç†çš„ä¸»å‡½æ•¸
    """
    print("ğŸœ å°ç£ç¾é£Ÿ CNN åˆ†é¡ - æ‰‹å‹•ç¡¬é«”é¸æ“‡æ¨¡å¼")
    print("Taiwan Food CNN Classification - Manual Hardware Selection")
    print("=" * 80)
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
    if not os.path.exists('models'):
        print("âŒ æ‰¾ä¸åˆ° models è³‡æ–™å¤¾")
        print("è«‹å…ˆåŸ·è¡Œ python train_pytorch.py é€²è¡Œè¨“ç·´")
        return
    
    model_files = [f for f in os.listdir('models') if f.endswith('.pth')]
    if not model_files:
        print("âŒ æ‰¾ä¸åˆ°è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆ")
        print("è«‹å…ˆåŸ·è¡Œ python train_pytorch.py é€²è¡Œè¨“ç·´")
        return
    
    # é¡¯ç¤ºå¯ç”¨æ¨¡å‹
    print("ğŸ“‚ å¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ:")
    for i, model_file in enumerate(model_files):
        model_path = os.path.join('models', model_file)
        model_size = os.path.getsize(model_path) / (1024*1024)  # MB
        print(f"  {i}. {model_file} ({model_size:.1f} MB)")
    
    # é¸æ“‡æ¨¡å‹
    while True:
        try:
            if len(model_files) == 1:
                model_idx = 0
                print(f"\nğŸ¯ è‡ªå‹•é¸æ“‡å”¯ä¸€æ¨¡å‹: {model_files[0]}")
                break
            else:
                model_input = input(f"\nğŸ‘‰ è«‹é¸æ“‡æ¨¡å‹ (0-{len(model_files)-1}) æˆ–æŒ‰ Enter ä½¿ç”¨æœ€æ–°æ¨¡å‹: ").strip()
                
                if model_input == "":
                    # ä½¿ç”¨æœ€æ–°æ¨¡å‹
                    latest_model = max(model_files, key=lambda x: os.path.getctime(os.path.join('models', x)))
                    model_idx = model_files.index(latest_model)
                    print(f"ğŸ¯ ä½¿ç”¨æœ€æ–°æ¨¡å‹: {latest_model}")
                    break
                else:
                    model_idx = int(model_input)
                    if 0 <= model_idx < len(model_files):
                        print(f"ğŸ¯ é¸æ“‡æ¨¡å‹: {model_files[model_idx]}")
                        break
                    else:
                        print(f"âš ï¸  è«‹è¼¸å…¥ 0-{len(model_files)-1} ä¹‹é–“çš„æ•¸å­—")
                        
        except ValueError:
            print("âš ï¸  è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼çµæŸ")
            return
    
    model_path = os.path.join('models', model_files[model_idx])
    
    # æª¢æ¸¬å¯ç”¨ç¡¬é«”
    available_devices, npu_available, gpu_available, amd_npu_available = detect_available_devices()
    
    # æä¾› NPU ä½¿ç”¨ç‡é¸é …
    if amd_npu_available:
        print(f"\nğŸš€ AMD NPU æ¨ç†æ¨¡å¼é¸æ“‡:")
        print("  1. ğŸ”¥ é«˜æ•ˆèƒ½æ¨¡å¼ (æœ€å¤§åŒ– NPU ä½¿ç”¨ç‡)")
        print("  2. ğŸ”§ æ¨™æº–æ¨¡å¼ (å¹³è¡¡æ•ˆèƒ½)")
        print("  3. ğŸ’» å…¶ä»–ç¡¬é«” (GPU/CPU)")
        
        while True:
            try:
                npu_choice = input("\nğŸ‘‰ è«‹é¸æ“‡ NPU æ¨¡å¼ (1-3): ").strip()
                
                if npu_choice == "1":
                    print("ğŸ”¥ ä½¿ç”¨é«˜æ•ˆèƒ½ AMD NPU æ¨¡å¼")
                    device_str = 'amd_npu_optimized'
                    break
                elif npu_choice == "2":
                    print("ğŸ”§ ä½¿ç”¨æ¨™æº– AMD NPU æ¨¡å¼")
                    device_str = 'amd_npu'
                    break
                elif npu_choice == "3":
                    print("ğŸ’» é¸æ“‡å…¶ä»–ç¡¬é«”...")
                    device_str = choose_device(available_devices, npu_available, gpu_available, amd_npu_available, manual_mode=True)
                    break
                else:
                    print("âš ï¸  è«‹è¼¸å…¥ 1ã€2 æˆ– 3")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹å¼çµæŸ")
                return
    else:
        # æ‰‹å‹•é¸æ“‡ç¡¬é«”
        device_str = choose_device(available_devices, npu_available, gpu_available, amd_npu_available, manual_mode=True)
    
    if device_str is None:
        print("âŒ æœªé¸æ“‡è£ç½®ï¼Œç¨‹å¼çµæŸ")
        return
    
    # è¨­å®šæ¸¬è©¦åƒæ•¸
    test_csv = 'archive/tw_food_101/tw_food_101_test_list.csv'
    test_img_dir = 'archive/tw_food_101/test'
    num_classes = 101
    batch_size = 32
    img_size = 224
    
    # NPU æœ€ä½³åŒ–åƒæ•¸èª¿æ•´
    if device_str == 'amd_npu_optimized':
        batch_size = 32  # æœ€ä½³åŒ–æ‰¹æ¬¡å¤§å°
        print(f"ğŸ”¥ é«˜æ•ˆèƒ½æ¨¡å¼ï¼šä½¿ç”¨æ‰¹æ¬¡å¤§å° {batch_size}")
    
    # æª¢æŸ¥æ¸¬è©¦è³‡æ–™
    if not os.path.exists(test_csv):
        print(f"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æ¸…å–®æª”æ¡ˆ: {test_csv}")
        return
    
    if not os.path.exists(test_img_dir):
        print(f"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦åœ–ç‰‡ç›®éŒ„: {test_img_dir}")
        return
    
    print(f"\nğŸ“‹ æ¨ç†è¨­å®š:")
    print(f"   æ¨¡å‹æª”æ¡ˆ: {model_files[model_idx]}")
    print(f"   æ¨ç†ç¡¬é«”: {device_str}")
    print(f"   æ¸¬è©¦åœ–ç‰‡: {test_img_dir}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   åœ–ç‰‡å°ºå¯¸: {img_size}x{img_size}")
    print("=" * 60)
    
    # ç¢ºèªé–‹å§‹æ¨ç†
    confirm = input("ğŸš€ æ˜¯å¦é–‹å§‹æ¨ç†ï¼Ÿ (Y/n): ").strip().lower()
    if confirm in ['n', 'no']:
        print("âŒ ä½¿ç”¨è€…å–æ¶ˆæ¨ç†")
        return
    
    # åŸ·è¡Œæ¨ç†
    try:
        if device_str == 'amd_npu_optimized':
            print("\nï¿½ ä½¿ç”¨é«˜æ•ˆèƒ½ AMD NPU æ¨¡å¼é€²è¡Œæ¨ç†...")
            from optimized_amd_npu import OptimizedAMDNPUInference
            
            # å»ºç«‹æœ€ä½³åŒ–æ¨ç†å¼•æ“
            npu_inference = OptimizedAMDNPUInference(
                model_path, 
                img_size=img_size,
                batch_size=batch_size,
                num_threads=6  # é«˜ä¸¦è¡Œè¨­å®š
            )
            
            # æº–å‚™æ¸¬è©¦åœ–ç‰‡è·¯å¾‘
            import glob
            test_images = []
            for i in range(100):  # æ¸¬è©¦å‰100å¼µåœ–ç‰‡
                for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:
                    img_path = os.path.join(test_img_dir, f"{i}{ext}")
                    if os.path.exists(img_path):
                        test_images.append(img_path)
                        break
            
            if test_images:
                print(f"ğŸ“¸ æ‰¾åˆ° {len(test_images)} å¼µæ¸¬è©¦åœ–ç‰‡")
                predictions = npu_inference.predict_image_batch(test_images)
                
                # å„²å­˜çµæœ
                results_file = "test_predictions_optimized_npu.csv"
                with open(results_file, 'w', encoding='utf-8') as f:
                    f.write("Id,Category,Path\n")
                    for pred in predictions:
                        f.write(f"{pred['id']},{pred['prediction']},{pred['path']}\n")
                
                print(f"âœ… çµæœå·²å„²å­˜è‡³: {results_file}")
            
            # æ¸…ç†
            npu_inference.shutdown()
            
        elif device_str == 'amd_npu':
            print("\nğŸ”§ ä½¿ç”¨æ¨™æº– AMD NPU æ¨¡å¼é€²è¡Œæ¨ç†...")
            evaluate_with_amd_npu(model_path, test_csv, test_img_dir, num_classes, batch_size, img_size)
        else:
            print(f"\nğŸ”§ ä½¿ç”¨ {device_str.upper()} é€²è¡Œæ¨ç†...")
            evaluate_standard_mode(model_path, test_csv, test_img_dir, num_classes, batch_size, img_size, device_str)
            
        print("\nğŸ‰ æ¨ç†å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·æ¨ç†")
    except Exception as e:
        print(f"\nâŒ æ¨ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        print("ğŸ’¡ å»ºè­°æª¢æŸ¥ç¡¬é«”ç›¸å®¹æ€§å’Œè³‡æ–™å®Œæ•´æ€§")

def show_hardware_info():
    """
    é¡¯ç¤ºç¡¬é«”è³‡è¨Šçš„è¼”åŠ©å‡½æ•¸
    """
    print("ğŸ” ç¡¬é«”è³‡è¨Šæª¢æ¸¬")
    print("=" * 40)
    
    available_devices, npu_available, gpu_available, amd_npu_available = detect_available_devices()
    
    print(f"\nğŸ“Š ç¡¬é«”æ”¯æ´ç¸½çµ:")
    print(f"   AMD NPU: {'âœ… å¯ç”¨' if amd_npu_available else 'âŒ ä¸å¯ç”¨'}")
    print(f"   å‚³çµ± NPU: {'âœ… å¯ç”¨' if npu_available else 'âŒ ä¸å¯ç”¨'}")
    print(f"   GPU (CUDA): {'âœ… å¯ç”¨' if gpu_available else 'âŒ ä¸å¯ç”¨'}")
    print(f"   CPU: âœ… å¯ç”¨")
    
    return available_devices, npu_available, gpu_available, amd_npu_available

def main():
    """
    ä¸»é¸å–®
    """
    while True:
        print("\nğŸœ å°ç£ç¾é£Ÿ CNN - æ‰‹å‹•ç¡¬é«”é¸æ“‡å·¥å…·")
        print("=" * 50)
        print("1. ğŸš€ é–‹å§‹æ‰‹å‹•ç¡¬é«”æ¨ç†")
        print("2. ğŸ” æª¢è¦–ç¡¬é«”è³‡è¨Š")
        print("3. âŒ é€€å‡ºç¨‹å¼")
        
        try:
            choice = input("\nğŸ‘‰ è«‹é¸æ“‡åŠŸèƒ½ (1-3): ").strip()
            
            if choice == "1":
                manual_device_inference()
            elif choice == "2":
                show_hardware_info()
                input("\næŒ‰ Enter éµç¹¼çºŒ...")
            elif choice == "3":
                print("\nğŸ‘‹ ç¨‹å¼çµæŸï¼Œæ„Ÿè¬ä½¿ç”¨ï¼")
                break
            else:
                print("âš ï¸  è«‹è¼¸å…¥ 1ã€2 æˆ– 3")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹å¼çµæŸï¼Œæ„Ÿè¬ä½¿ç”¨ï¼")
            break

if __name__ == '__main__':
    main()