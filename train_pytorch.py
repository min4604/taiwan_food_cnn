import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
from pytorch_model import get_model
from pytorch_data_loader import get_dataloaders
from tqdm import tqdm
import os

def check_gpu():
    """è©³ç´°æª¢æŸ¥ GPU å¯ç”¨æ€§"""
    print("=" * 60)
    print("ğŸ” GPU ç’°å¢ƒæª¢æ¸¬")
    print("=" * 60)
    
    gpu_available = torch.cuda.is_available()
    
    if gpu_available:
        device_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        device_name = torch.cuda.get_device_name(current_device)
        
        print(f"âœ… CUDA å¯ç”¨: {torch.version.cuda}")
        print(f"ğŸ¯ GPU æ•¸é‡: {device_count}")
        print(f"ğŸš€ ç•¶å‰ GPU: {device_name}")
        
        # é¡¯ç¤º GPU è¨˜æ†¶é«”è³‡è¨Š
        if device_count > 0:
            for i in range(device_count):
                props = torch.cuda.get_device_properties(i)
                memory = props.total_memory / 1024**3  # è½‰æ›ç‚º GB
                print(f"   GPU {i}: {props.name} ({memory:.1f} GB)")
                
        print(f"ğŸ”§ PyTorch ç‰ˆæœ¬: {torch.__version__}")
    else:
        print("âŒ CUDA ä¸å¯ç”¨")
        print("ğŸ’¡ å»ºè­°:")
        print("   1. ç¢ºèªæ‚¨çš„é›»è…¦æœ‰ NVIDIA GPU")
        print("   2. å®‰è£ NVIDIA é©…å‹•ç¨‹å¼")
        print("   3. åŸ·è¡Œ install_pytorch_gpu.bat å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch")
        print(f"ğŸ”§ ç•¶å‰ PyTorch ç‰ˆæœ¬: {torch.__version__}")
    
    print("=" * 60)
    return gpu_available

def detect_model_architecture_from_file(model_path):
    """å¾æ¨¡å‹æª”æ¡ˆæª¢æ¸¬æ¶æ§‹é¡å‹"""
    filename = os.path.basename(model_path).lower()
    
    if 'efficientnet_b3' in filename:
        return 'efficientnet_b3'
    elif 'convnext_tiny' in filename:
        return 'convnext_tiny'
    elif 'regnet_y' in filename:
        return 'regnet_y'
    elif 'vit' in filename:
        return 'vit'
    elif 'resnet50' in filename:
        return 'resnet50'
    else:
        # å˜—è©¦å¾æ¨¡å‹å…§å®¹æª¢æ¸¬
        try:
            state_dict = torch.load(model_path, map_location='cpu')
            keys = list(state_dict.keys())
            
            # æ ¹æ“š state_dict çš„éµå€¼æª¢æ¸¬æ¶æ§‹
            if any('features' in key for key in keys):
                if any('block' in key for key in keys):
                    return 'efficientnet_b3'  # EfficientNet ç‰¹å¾µ
                elif any('stages' in key for key in keys):
                    return 'convnext_tiny'    # ConvNeXt ç‰¹å¾µ
                else:
                    return 'efficientnet_b3'  # é è¨­ç‚º EfficientNet
            elif any('layer' in key for key in keys):
                return 'resnet50'             # ResNet ç‰¹å¾µ
            elif any('blocks' in key for key in keys):
                return 'vit'                  # ViT ç‰¹å¾µ
            else:
                return 'resnet50'             # é è¨­ç‚º ResNet50
        except:
            return 'resnet50'                 # é è¨­ç‚º ResNet50

def choose_model_architecture():
    """é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹æ¶æ§‹"""
    print("\n" + "=" * 60)
    print("ğŸ—ï¸  é¸æ“‡æ¨¡å‹æ¶æ§‹")
    print("=" * 60)
    
    models = {
        '1': ('resnet50', 'ResNet50 (åŸºç¤æ¨¡å‹)'),
        '2': ('efficientnet_b3', 'EfficientNet-B3 (æ¨è–¦ï¼Œæ•ˆèƒ½ä½³)'),
        '3': ('convnext_tiny', 'ConvNeXt-Tiny (ç¾ä»£æ¶æ§‹)'),
        '4': ('regnet_y', 'RegNet-Y (é«˜æ•ˆç¶²è·¯)'),
        '5': ('vit', 'Vision Transformer (æ³¨æ„åŠ›æ©Ÿåˆ¶)')
    }
    
    for key, (model_name, description) in models.items():
        print(f"{key}. {description}")
    
    while True:
        try:
            choice = input("\nè«‹é¸æ“‡æ¨¡å‹æ¶æ§‹ (1-5): ").strip()
            if choice in models:
                selected_model, description = models[choice]
                print(f"âœ… é¸æ“‡äº†: {description}")
                return selected_model
            else:
                print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥ 1-5")
        except KeyboardInterrupt:
            print("\nğŸš« å–æ¶ˆé¸æ“‡ï¼Œé€€å‡ºç¨‹å¼")
            exit(0)

def choose_model_to_continue():
    """é¸æ“‡è¦ç¹¼çºŒè¨“ç·´çš„æ¨¡å‹ï¼Œä¸¦è‡ªå‹•æª¢æ¸¬æ¶æ§‹"""
    print("\n" + "=" * 60)
    print("ğŸ¯ é¸æ“‡è¨“ç·´æ¨¡å¼")
    print("=" * 60)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„æ¨¡å‹
    models_dir = 'models'
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
        print("ğŸ“ å»ºç«‹ models ç›®éŒ„")
        model_architecture = choose_model_architecture()
        return None, 0, model_architecture
    
    # ç²å–æ‰€æœ‰ .pth æ¨¡å‹æª”æ¡ˆ
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
    
    if not model_files:
        print("ğŸ“‹ æ²’æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹ï¼Œå°‡å¾é ­é–‹å§‹è¨“ç·´")
        model_architecture = choose_model_architecture()
        return None, 0, model_architecture
    
    # é¡¯ç¤ºé¸é …
    print("è«‹é¸æ“‡è¨“ç·´æ¨¡å¼:")
    print("0. ğŸ†• å¾é ­é–‹å§‹è¨“ç·´ (æ–°æ¨¡å‹)")
    
    # é¡¯ç¤ºå¯ç”¨çš„æ¨¡å‹æª”æ¡ˆ
    for i, model_file in enumerate(model_files, 1):
        # å˜—è©¦å¾æª”åä¸­æå– epoch è³‡è¨Š
        if 'epoch' in model_file:
            print(f"{i}. ğŸ”„ ç¹¼çºŒè¨“ç·´: {model_file}")
        else:
            print(f"{i}. ğŸ”„ ç¹¼çºŒè¨“ç·´: {model_file}")
    
    print("-" * 60)
    
    # ç²å–ç”¨æˆ¶é¸æ“‡
    while True:
        try:
            choice = input(f"è«‹è¼¸å…¥é¸æ“‡ (0-{len(model_files)}): ").strip()
            choice = int(choice)
            
            if choice == 0:
                print("âœ… é¸æ“‡å¾é ­é–‹å§‹è¨“ç·´")
                # è®“ç”¨æˆ¶é¸æ“‡æ¶æ§‹
                model_architecture = choose_model_architecture()
                return None, 0, model_architecture
            elif 1 <= choice <= len(model_files):
                selected_model = model_files[choice - 1]
                print(f"âœ… é¸æ“‡ç¹¼çºŒè¨“ç·´: {selected_model}")
                
                # æª¢æ¸¬æ¨¡å‹æ¶æ§‹
                model_path = os.path.join(models_dir, selected_model)
                model_architecture = detect_model_architecture_from_file(model_path)
                print(f"ğŸ—ï¸  æª¢æ¸¬åˆ°æ¨¡å‹æ¶æ§‹: {model_architecture}")
                
                # å˜—è©¦å¾æª”åä¸­æå– epoch æ•¸
                start_epoch = 0
                try:
                    if 'epoch' in selected_model:
                        # å‡è¨­æª”åæ ¼å¼ç‚º taiwan_food_resnet50_epoch10.pth
                        epoch_part = selected_model.split('epoch')[1].split('.')[0]
                        start_epoch = int(epoch_part)
                        print(f"ğŸ“Š æª¢æ¸¬åˆ°å¾ç¬¬ {start_epoch} å€‹ epoch ç¹¼çºŒè¨“ç·´")
                    else:
                        print("âš ï¸  ç„¡æ³•å¾æª”åæª¢æ¸¬ epochï¼Œå°‡å¾ epoch 0 é–‹å§‹è¨ˆæ•¸")
                except:
                    print("âš ï¸  ç„¡æ³•è§£æ epoch è³‡è¨Šï¼Œå°‡å¾ epoch 0 é–‹å§‹è¨ˆæ•¸")
                
                return os.path.join(models_dir, selected_model), start_epoch, model_architecture
            else:
                print(f"âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥ 0-{len(model_files)} ä¹‹é–“çš„æ•¸å­—")
        except ValueError:
            print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
        except KeyboardInterrupt:
            print("\nğŸš« å–æ¶ˆé¸æ“‡ï¼Œé€€å‡ºç¨‹å¼")
            exit(0)

def main():
    # è³‡æ–™è·¯å¾‘
    train_csv = 'archive/tw_food_101/tw_food_101_train.csv'
    # æ³¨æ„ï¼šæ¸¬è©¦é›†ä¸åƒèˆ‡è¨“ç·´ï¼Œåƒ…ç”¨æ–¼æœ€çµ‚è©•ä¼°
    test_csv = 'archive/tw_food_101/tw_food_101_test_list.csv'  
    train_img_dir = 'archive/tw_food_101/train'
    test_img_dir = 'archive/tw_food_101/test'
    num_classes = 101
    total_epochs = 50
    lr = 1e-3
    img_size = 224

    gpu = check_gpu()
    device = torch.device('cuda' if gpu else 'cpu')
    
    # æ ¹æ“š GPU/CPU èª¿æ•´æ‰¹æ¬¡å¤§å°
    if gpu:
        batch_size = 32  # GPU å¯ä»¥è™•ç†æ›´å¤§çš„æ‰¹æ¬¡
        print(f"ğŸš€ ä½¿ç”¨ GPU è¨“ç·´ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
    else:
        batch_size = 16  # CPU ä½¿ç”¨è¼ƒå°æ‰¹æ¬¡é¿å…è¨˜æ†¶é«”ä¸è¶³
        print(f"ğŸ’» ä½¿ç”¨ CPU è¨“ç·´ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        
    print()

    # é¸æ“‡è¦ç¹¼çºŒè¨“ç·´çš„æ¨¡å‹ï¼ˆé€™æœƒè‡ªå‹•æª¢æ¸¬æ¶æ§‹ï¼‰
    model_path, start_epoch, model_architecture = choose_model_to_continue()
    remaining_epochs = total_epochs - start_epoch

    # DataLoader - åªä½¿ç”¨è¨“ç·´é›†é€²è¡Œè¨“ç·´å’Œé©—è­‰
    # æ¸¬è©¦é›†ä¸åƒèˆ‡ä»»ä½•è¨“ç·´éç¨‹
    train_loader, val_loader, _ = get_dataloaders(
        train_csv, test_csv, train_img_dir, test_img_dir, batch_size, img_size
    )
    
    print("ğŸ“Š è³‡æ–™é›†è³‡è¨Š:")
    print(f"   è¨“ç·´é›†å¤§å°: {len(train_loader.dataset)} (ç”¨æ–¼è¨“ç·´)")
    print(f"   é©—è­‰é›†å¤§å°: {len(val_loader.dataset)} (å¾è¨“ç·´é›†åˆ†å‰²ï¼Œç”¨æ–¼é©—è­‰)")
    print(f"   âš ï¸  æ¸¬è©¦é›†: ä¸åƒèˆ‡è¨“ç·´éç¨‹ï¼Œåƒ…ä¾›æœ€çµ‚è©•ä¼°ä½¿ç”¨")
    print()

    # æ ¹æ“šé¸æ“‡å‰µå»ºæ¨¡å‹
    print(f"ğŸ—ï¸  å‰µå»ºæ¨¡å‹: {model_architecture}")
    model = get_model(model_architecture, num_classes=num_classes, dropout_rate=0.3).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    # è¼‰å…¥å·²å­˜åœ¨çš„æ¨¡å‹ï¼ˆå¦‚æœé¸æ“‡äº†ï¼‰
    if model_path:
        try:
            model.load_state_dict(torch.load(model_path, map_location=device))
            print(f"âœ… æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_path}")
            print(f"ğŸ”„ å¾ epoch {start_epoch + 1} é–‹å§‹ç¹¼çºŒè¨“ç·´")
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            print("ğŸ†• å°‡å¾é ­é–‹å§‹è¨“ç·´")
            start_epoch = 0
            remaining_epochs = total_epochs
    else:
        print("ğŸ†• å¾é ­é–‹å§‹è¨“ç·´æ–°æ¨¡å‹")
        
    print(f"ğŸ“ˆ è¨“ç·´è¨ˆç•«: å¾ epoch {start_epoch + 1} åˆ° epoch {total_epochs} (å…± {remaining_epochs} å€‹ epochs)")
    print("=" * 60)

    # Training loop
    for epoch in range(start_epoch, total_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{total_epochs}", ncols=100)
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
            pbar.set_postfix({
                'loss': f'{running_loss/total:.4f}',
                'acc': f'{correct/total:.4f}'
            })
        print(f"è¨“ç·´ Loss: {running_loss/total:.4f} | è¨“ç·´ Acc: {correct/total:.4f}")

        # é©—è­‰
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc="é©—è­‰ä¸­", ncols=80, leave=False)
            for images, labels in val_pbar:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)
                _, predicted = outputs.max(1)
                val_correct += predicted.eq(labels).sum().item()
                val_total += labels.size(0)
                val_pbar.set_postfix({
                    'val_loss': f'{val_loss/val_total:.4f}',
                    'val_acc': f'{val_correct/val_total:.4f}'
                })
        
        print(f"é©—è­‰ Loss: {val_loss/val_total:.4f} | é©—è­‰ Acc: {val_correct/val_total:.4f}")
        print("-" * 60)

        # ä¿å­˜æ¨¡å‹
        os.makedirs('models', exist_ok=True)
        model_filename = f'taiwan_food_{model_architecture}_epoch{epoch+1}.pth'
        torch.save(model.state_dict(), f'models/{model_filename}')
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: models/{model_filename}")
        print()

if __name__ == '__main__':
    main()
