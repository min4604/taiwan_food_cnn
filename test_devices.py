#!/usr/bin/env python3
"""
NPU/GPU/CPU è£ç½®æª¢æ¸¬æ¸¬è©¦è…³æœ¬
"""

import torch
import sys

def comprehensive_device_detection():
    """
    å…¨é¢æª¢æ¸¬ç³»çµ±ä¸­å¯ç”¨çš„è¨ˆç®—è£ç½®
    """
    print("ğŸ” ç³»çµ±è¨ˆç®—è£ç½®æª¢æ¸¬å ±å‘Š")
    print("=" * 60)
    
    # PyTorch ç‰ˆæœ¬
    print(f"ğŸ“¦ PyTorch ç‰ˆæœ¬: {torch.__version__}")
    
    # CPU è³‡è¨Š
    print("ğŸ’» CPU:")
    print(f"   å¯ç”¨: âœ…")
    print(f"   åŸ·è¡Œç·’æ•¸: {torch.get_num_threads()}")
    
    # CUDA GPU æª¢æ¸¬
    print("\nğŸ® CUDA GPU:")
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"   å¯ç”¨: âœ… ({gpu_count} å€‹è£ç½®)")
        print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / (1024**3)
            print(f"   GPU {i}: {props.name} ({memory_gb:.1f} GB)")
    else:
        print("   å¯ç”¨: âŒ")
    
    # NPU æª¢æ¸¬ (å¤šç¨®æ–¹å¼)
    print("\nğŸš€ NPU (ç¥ç¶“è™•ç†å–®å…ƒ):")
    npu_found = False
    
    # AMD Ryzen AI NPU æª¢æ¸¬
    print("   AMD Ryzen AI NPU:")
    try:
        # æª¢æ¸¬ DirectML
        import onnxruntime as ort
        providers = ort.get_available_providers()
        if 'DmlExecutionProvider' in providers:
            print("   âœ… ONNX Runtime DirectML å¯ç”¨")
            npu_found = True
            
            # å˜—è©¦æª¢æ¸¬å…·é«”ç¡¬é«”
            import platform
            import subprocess
            if platform.system() == 'Windows':
                try:
                    result = subprocess.run(['wmic', 'cpu', 'get', 'name'], 
                                          capture_output=True, text=True, timeout=5)
                    if 'AMD Ryzen' in result.stdout and 'AI' in result.stdout:
                        print("   ğŸ¯ æª¢æ¸¬åˆ° AMD Ryzen AI è™•ç†å™¨")
                        npu_found = True
                    else:
                        print("   âš ï¸  æœªæª¢æ¸¬åˆ° AMD Ryzen AI è™•ç†å™¨")
                except:
                    print("   âš ï¸  ç„¡æ³•æª¢æ¸¬è™•ç†å™¨å‹è™Ÿ")
        else:
            print("   âŒ DirectML ä¸å¯ç”¨")
            print("   ğŸ’¡ è«‹åŸ·è¡Œ install_amd_npu.bat å®‰è£æ”¯æ´")
    except ImportError:
        print("   âŒ ONNX Runtime æœªå®‰è£")
        print("   ğŸ’¡ è«‹åŸ·è¡Œ: pip install onnxruntime-directml")
    except Exception as e:
        print(f"   âŒ æª¢æ¸¬å¤±æ•—: {e}")
    
    # torch-directml æª¢æ¸¬
    try:
        import torch_directml
        if torch_directml.is_available():
            print("   âœ… torch-directml å¯ç”¨")
            npu_found = True
    except ImportError:
        print("   â„¹ï¸  torch-directml æœªå®‰è£ (å¯é¸)")
    except Exception as e:
        print(f"   âš ï¸  torch-directml æª¢æ¸¬å¤±æ•—: {e}")
    
    # æ–¹å¼ 1: torch.npu (è¯ç‚ºç­‰)
    try:
        if hasattr(torch, 'npu'):
            if torch.npu.is_available():
                npu_count = torch.npu.device_count()
                print(f"   å¯ç”¨ (torch.npu): âœ… ({npu_count} å€‹è£ç½®)")
                for i in range(npu_count):
                    try:
                        name = torch.npu.get_device_name(i)
                        print(f"   NPU {i}: {name}")
                    except:
                        print(f"   NPU {i}: æœªçŸ¥å‹è™Ÿ")
                npu_found = True
            else:
                print("   torch.npu å­˜åœ¨ä½†ä¸å¯ç”¨")
        else:
            print("   torch.npu: ä¸å­˜åœ¨")
    except Exception as e:
        print(f"   torch.npu æª¢æ¸¬éŒ¯èª¤: {e}")
    
    # æ–¹å¼ 2: torch.backends.npu
    try:
        if hasattr(torch.backends, 'npu'):
            if torch.backends.npu.is_available():
                print("   å¯ç”¨ (backends.npu): âœ…")
                npu_found = True
            else:
                print("   backends.npu å­˜åœ¨ä½†ä¸å¯ç”¨")
        else:
            print("   torch.backends.npu: ä¸å­˜åœ¨")
    except Exception as e:
        print(f"   backends.npu æª¢æ¸¬éŒ¯èª¤: {e}")
    
    # æ–¹å¼ 3: MPS (Apple Silicon)
    if hasattr(torch.backends, 'mps'):
        print("\nğŸ MPS (Apple Silicon):")
        try:
            if torch.backends.mps.is_available():
                print("   å¯ç”¨: âœ…")
                npu_found = True
            else:
                print("   å¯ç”¨: âŒ")
        except:
            print("   æª¢æ¸¬å¤±æ•—")
    
    if not npu_found:
        print("   æ•´é«” NPU æ”¯æ´: âŒ")
        print("   ğŸ’¡ å¯èƒ½éœ€è¦:")
        print("      - å®‰è£ NPU å°ˆç”¨ PyTorch ç‰ˆæœ¬")
        print("      - å®‰è£ NPU é©…å‹•ç¨‹å¼")
        print("      - ç¢ºèªç¡¬é«”æ”¯æ´")
    
    # å»ºè­°çš„ä½¿ç”¨é †åº
    print("\nğŸ¯ å»ºè­°ä½¿ç”¨é †åº:")
    devices = []
    if npu_found:
        devices.append("ğŸ¥‡ NPU (æœ€é«˜æ•ˆèƒ½)")
    if torch.cuda.is_available():
        devices.append("ğŸ¥ˆ GPU (é«˜æ•ˆèƒ½)")
    devices.append("ğŸ¥‰ CPU (ç©©å®š)")
    
    for i, device in enumerate(devices, 1):
        print(f"   {i}. {device}")
    
    print("=" * 60)

def test_device_creation():
    """
    æ¸¬è©¦ä¸åŒè£ç½®çš„ tensor å»ºç«‹
    """
    print("\nğŸ§ª è£ç½®åŠŸèƒ½æ¸¬è©¦")
    print("-" * 40)
    
    # CPU æ¸¬è©¦
    try:
        cpu_tensor = torch.randn(3, 3, device='cpu')
        print("âœ… CPU tensor å»ºç«‹æˆåŠŸ")
    except Exception as e:
        print(f"âŒ CPU tensor å»ºç«‹å¤±æ•—: {e}")
    
    # GPU æ¸¬è©¦
    if torch.cuda.is_available():
        try:
            gpu_tensor = torch.randn(3, 3, device='cuda:0')
            print("âœ… GPU tensor å»ºç«‹æˆåŠŸ")
        except Exception as e:
            print(f"âŒ GPU tensor å»ºç«‹å¤±æ•—: {e}")
    
    # NPU æ¸¬è©¦
    npu_devices = []
    if hasattr(torch, 'npu') and torch.npu.is_available():
        npu_devices.append('npu:0')
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        npu_devices.append('mps')
    
    for device in npu_devices:
        try:
            npu_tensor = torch.randn(3, 3, device=device)
            print(f"âœ… {device.upper()} tensor å»ºç«‹æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {device.upper()} tensor å»ºç«‹å¤±æ•—: {e}")

if __name__ == '__main__':
    comprehensive_device_detection()
    test_device_creation()
    
    print("\nğŸ’¡ å¦‚æœéœ€è¦ NPU æ”¯æ´ï¼Œè«‹ç¢ºèª:")
    print("   1. ç¡¬é«”æ˜¯å¦æ”¯æ´ NPU")
    print("   2. æ˜¯å¦å®‰è£äº†æ­£ç¢ºçš„ NPU é©…å‹•")
    print("   3. æ˜¯å¦ä½¿ç”¨äº†æ”¯æ´ NPU çš„ PyTorch ç‰ˆæœ¬")
    print("   4. ç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢ºè¨­å®š")