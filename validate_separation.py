#!/usr/bin/env python3
"""
é©—è­‰å°ç£ç¾é£Ÿè³‡æ–™é›†çš„è¨“ç·´/æ¸¬è©¦åˆ†é›¢
ç¢ºä¿æ¸¬è©¦è³‡æ–™å®Œå…¨ä¸åƒèˆ‡è¨“ç·´
"""

import os
import pandas as pd
from data_loader import TaiwanFoodDataLoader

def validate_data_separation():
    """è©³ç´°é©—è­‰è³‡æ–™åˆ†é›¢"""
    print("=" * 60)
    print("å°ç£ç¾é£Ÿè³‡æ–™é›†åˆ†é›¢é©—è­‰")
    print("=" * 60)
    
    data_dir = "archive/tw_food_101"
    
    # 1. æª¢æŸ¥ CSV æª”æ¡ˆ
    train_csv = os.path.join(data_dir, "tw_food_101_train.csv")
    test_csv = os.path.join(data_dir, "tw_food_101_test_list.csv")
    
    if not os.path.exists(train_csv):
        print(f"âŒ æ‰¾ä¸åˆ°è¨“ç·´ CSV: {train_csv}")
        return False
    
    if not os.path.exists(test_csv):
        print(f"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦ CSV: {test_csv}")
        return False
    
    # 2. è¼‰å…¥è³‡æ–™
    print("ğŸ“– è¼‰å…¥è³‡æ–™...")
    df_train = pd.read_csv(train_csv, header=None, names=['index', 'class_id', 'image_path'])
    df_test = pd.read_csv(test_csv, header=None, names=['index', 'image_path'])
    
    print(f"è¨“ç·´è³‡æ–™: {len(df_train)} ç­†")
    print(f"æ¸¬è©¦è³‡æ–™: {len(df_test)} ç­†")
    
    # 3. æª¢æŸ¥æª”æ¡ˆè·¯å¾‘é‡ç–Š
    print("\nğŸ” æª¢æŸ¥æª”æ¡ˆé‡ç–Š...")
    train_paths = set(df_train['image_path'].tolist())
    test_paths = set(df_test['image_path'].tolist())
    
    overlap = train_paths.intersection(test_paths)
    
    if overlap:
        print(f"âŒ ç™¼ç¾ {len(overlap)} å€‹é‡ç–Šæª”æ¡ˆï¼")
        print("é‡ç–Šæª”æ¡ˆ:")
        for i, path in enumerate(sorted(overlap)):
            print(f"  {i+1:3d}. {path}")
            if i >= 10:  # åªé¡¯ç¤ºå‰10å€‹
                print(f"      ... é‚„æœ‰ {len(overlap) - 10} å€‹")
                break
        return False
    else:
        print("âœ… è¨“ç·´å’Œæ¸¬è©¦æª”æ¡ˆå®Œå…¨åˆ†é›¢")
    
    # 4. æª¢æŸ¥æª”æ¡ˆå­˜åœ¨æ€§
    print("\nğŸ“ æª¢æŸ¥æª”æ¡ˆå­˜åœ¨æ€§...")
    
    # æª¢æŸ¥è¨“ç·´æª”æ¡ˆ
    missing_train = 0
    for i, path in enumerate(df_train['image_path']):
        full_path = os.path.join(data_dir, path)
        if not os.path.exists(full_path):
            missing_train += 1
            if missing_train <= 5:  # åªé¡¯ç¤ºå‰5å€‹ç¼ºå¤±æª”æ¡ˆ
                print(f"  ç¼ºå¤±è¨“ç·´æª”æ¡ˆ: {path}")
    
    # æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆ
    missing_test = 0
    for i, path in enumerate(df_test['image_path']):
        full_path = os.path.join(data_dir, path)
        if not os.path.exists(full_path):
            missing_test += 1
            if missing_test <= 5:  # åªé¡¯ç¤ºå‰5å€‹ç¼ºå¤±æª”æ¡ˆ
                print(f"  ç¼ºå¤±æ¸¬è©¦æª”æ¡ˆ: {path}")
    
    print(f"è¨“ç·´æª”æ¡ˆ: {len(df_train) - missing_train}/{len(df_train)} å­˜åœ¨")
    print(f"æ¸¬è©¦æª”æ¡ˆ: {len(df_test) - missing_test}/{len(df_test)} å­˜åœ¨")
    
    # 5. æª¢æŸ¥é¡åˆ¥åˆ†å¸ƒ
    print("\nğŸ“Š æª¢æŸ¥è¨“ç·´è³‡æ–™é¡åˆ¥åˆ†å¸ƒ...")
    class_counts = df_train['class_id'].value_counts().sort_index()
    
    print(f"ç¸½é¡åˆ¥æ•¸: {len(class_counts)}")
    print(f"é¡åˆ¥ç¯„åœ: {class_counts.index.min()} - {class_counts.index.max()}")
    print(f"å¹³å‡æ¯é¡æ¨£æœ¬æ•¸: {class_counts.mean():.1f}")
    print(f"æœ€å°‘æ¨£æœ¬æ•¸: {class_counts.min()}")
    print(f"æœ€å¤šæ¨£æœ¬æ•¸: {class_counts.max()}")
    
    # 6. æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨
    print("\nğŸ”§ æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨...")
    try:
        loader = TaiwanFoodDataLoader(data_dir=data_dir)
        
        # æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆåˆ—è¡¨æ˜¯å¦æ­£ç¢ºè¼‰å…¥
        expected_test_files = set(df_test['image_path'].tolist())
        actual_test_files = loader.test_files
        
        if expected_test_files == actual_test_files:
            print("âœ… è³‡æ–™è¼‰å…¥å™¨æ­£ç¢ºè¼‰å…¥æ¸¬è©¦æª”æ¡ˆåˆ—è¡¨")
        else:
            print("âŒ è³‡æ–™è¼‰å…¥å™¨æ¸¬è©¦æª”æ¡ˆåˆ—è¡¨ä¸æ­£ç¢º")
            missing_in_loader = expected_test_files - actual_test_files
            extra_in_loader = actual_test_files - expected_test_files
            
            if missing_in_loader:
                print(f"  è¼‰å…¥å™¨ä¸­ç¼ºå¤± {len(missing_in_loader)} å€‹æ¸¬è©¦æª”æ¡ˆ")
            if extra_in_loader:
                print(f"  è¼‰å…¥å™¨ä¸­å¤šå‡º {len(extra_in_loader)} å€‹æª”æ¡ˆ")
        
        # æ¸¬è©¦å¯¦éš›è¼‰å…¥å°‘é‡è³‡æ–™
        print("\nğŸ§ª æ¸¬è©¦å¯¦éš›è³‡æ–™è¼‰å…¥...")
        try:
            (X_train, y_train), (X_val, y_val) = loader.load_dataset_from_csv('train', validation_split=0.1)
            print(f"âœ… æˆåŠŸè¼‰å…¥è¨“ç·´è³‡æ–™: {X_train.shape}")
            print(f"âœ… æˆåŠŸè¼‰å…¥é©—è­‰è³‡æ–™: {X_val.shape}")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ¸¬è©¦æª”æ¡ˆæ··å…¥è¨“ç·´è³‡æ–™ï¼ˆé€™åœ¨æ–°çš„è¼‰å…¥å™¨ä¸­æ‡‰è©²ä¸æœƒç™¼ç”Ÿï¼‰
            print("   å·²ç¢ºä¿æ¸¬è©¦æª”æ¡ˆå®Œå…¨ä¸åƒèˆ‡è¨“ç·´")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥è¨“ç·´è³‡æ–™å¤±æ•—: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ å»ºç«‹è³‡æ–™è¼‰å…¥å™¨å¤±æ•—: {e}")
        return False
    
    # 7. ç¸½çµ
    print("\n" + "=" * 60)
    success = (
        len(overlap) == 0 and
        missing_train == 0 and
        missing_test == 0
    )
    
    if success:
        print("ğŸ‰ é©—è­‰æˆåŠŸï¼")
        print("âœ… è¨“ç·´å’Œæ¸¬è©¦è³‡æ–™å®Œå…¨åˆ†é›¢")
        print("âœ… æ‰€æœ‰æª”æ¡ˆéƒ½å­˜åœ¨")
        print("âœ… è³‡æ–™è¼‰å…¥å™¨æ­£ç¢ºå·¥ä½œ")
        print("ğŸš€ å¯ä»¥å®‰å…¨é–‹å§‹è¨“ç·´")
    else:
        print("âš ï¸  é©—è­‰ç™¼ç¾å•é¡Œ")
        if overlap:
            print("âŒ è¨“ç·´å’Œæ¸¬è©¦è³‡æ–™æœ‰é‡ç–Š")
        if missing_train > 0:
            print(f"âŒ ç¼ºå¤± {missing_train} å€‹è¨“ç·´æª”æ¡ˆ")
        if missing_test > 0:
            print(f"âŒ ç¼ºå¤± {missing_test} å€‹æ¸¬è©¦æª”æ¡ˆ")
        print("è«‹ä¿®å¾©å•é¡Œå¾Œé‡æ–°é©—è­‰")
    
    print("=" * 60)
    return success

if __name__ == "__main__":
    validate_data_separation()